{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDoc79j0WFHQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import re\n",
        "import calendar\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlHXlOiNWf4M"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Raw_Dataset\\Customer_comment.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8_QaSmTLCcj"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVBUD0g8Wfqi"
      },
      "source": [
        "This code performs sentiment analysis on airline customer reviews to understand passengersâ€™ overall emotions and opinions. It calculates a sentiment score for each review using VADER and categorizes them as positive, neutral, or negative. The results are then visualized in a bar chart showing how reviews are distributed across these categories. This analysis helps identify the general satisfaction level of travelers and sets the stage for deeper insights, such as exploring what factors contribute most to negative or positive experiences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8uhnBfLL-Qu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZp-q7HcWffv"
      },
      "outputs": [],
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sentence_level_sentiment(text):\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return 0.0\n",
        "    sentences = sent_tokenize(text)\n",
        "    scores = [sia.polarity_scores(s)['compound'] for s in sentences]\n",
        "    return sum(scores) / len(scores)\n",
        "\n",
        "df['Sentiment_Score'] = df['Review_content'].apply(sentence_level_sentiment)\n",
        "\n",
        "def label_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['Sentiment_Analysis'] = df['Sentiment_Score'].apply(label_sentiment)\n",
        "\n",
        "sns.countplot(x='Sentiment_Analysis', data=df, order=['Positive', 'Neutral', 'Negative'], palette='coolwarm')\n",
        "plt.title('Sentiment Distribution of Airline Reviews')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "545fa1bf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tZZ1ThQWfEX"
      },
      "outputs": [],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "import numpy as np\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"airline_data_cleaning\")\n",
        "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
        "\n",
        "def get_location(lat, lon):\n",
        "    try:\n",
        "        if pd.notna(lat) and pd.notna(lon):\n",
        "            location = reverse((lat, lon), language='en')\n",
        "            if location and location.address:\n",
        "                addr = location.raw.get('address', {})\n",
        "                city = addr.get('city') or addr.get('town') or addr.get('village') or addr.get('state')\n",
        "                return city if city else location.address\n",
        "    except:\n",
        "        return np.nan\n",
        "    return np.nan\n",
        "\n",
        "# Fill missing Start_Location\n",
        "mask_start = df['Start_Location'].isna() & df['Start_Latitude'].notna() & df['Start_Longitude'].notna()\n",
        "df.loc[mask_start, 'Start_Location'] = df.loc[mask_start].apply(\n",
        "    lambda row: get_location(row['Start_Latitude'], row['Start_Longitude']), axis=1\n",
        ")\n",
        "\n",
        "# Fill missing End_Location\n",
        "mask_end = df['End_Location'].isna() & df['End_Latitude'].notna() & df['End_Longitude'].notna()\n",
        "df.loc[mask_end, 'End_Location'] = df.loc[mask_end].apply(\n",
        "    lambda row: get_location(row['End_Latitude'], row['End_Longitude']), axis=1\n",
        ")\n",
        "\n",
        "print(\"âœ… Missing Start and End locations filled (where coordinates available).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouSM_2STWe47"
      },
      "source": [
        "This script automatically fills missing latitude and longitude values for both Start_Location and End_Location in the airline reviews dataset.\n",
        "\n",
        "ðŸ” How It Works\n",
        "\n",
        "Cleans location names using the clean_location_name() function â€” removing unnecessary words like \"airport\", punctuation, and extra spaces.\n",
        "\n",
        "Uses the Nominatim API (via geopy) to geocode cleaned location names and retrieve accurate latitude and longitude values.\n",
        "\n",
        "Iterates through missing entries in both start and end coordinates:\n",
        "\n",
        "If valid coordinates are found, they are added to the dataset.\n",
        "\n",
        "If not, a warning is printed.\n",
        "\n",
        "Reports progress and summary of remaining missing values.\n",
        "\n",
        "âœ… This step ensures complete and consistent geolocation data for all routes, improving accuracy for mapping and spatial visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYNdCIYmWes4"
      },
      "outputs": [],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"airline_location_filler\")\n",
        "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
        "\n",
        "def clean_location_name(name):\n",
        "    if not isinstance(name, str):\n",
        "        return np.nan\n",
        "    name = name.lower()\n",
        "    name = re.sub(r'\\([^)]*\\)', '', name)  # remove text in parentheses\n",
        "    name = re.sub(r'\\b(international|airport|airpt|airlines?|terminal|int|intl)\\b', '', name)\n",
        "    name = re.sub(r'[-,]', ' ', name)\n",
        "    name = re.sub(r'\\s+', ' ', name)\n",
        "    return name.strip().title()\n",
        "\n",
        "def get_lat_lon(location):\n",
        "    try:\n",
        "        loc = geocode(location)\n",
        "        if loc:\n",
        "            return loc.latitude, loc.longitude\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "    return np.nan, np.nan\n",
        "\n",
        "# ---------- Fill missing START coordinates ----------\n",
        "missing_start = df[df['Start_Latitude'].isna() | df['Start_Longitude'].isna()]\n",
        "\n",
        "for idx, row in missing_start.iterrows():\n",
        "    cleaned = clean_location_name(row['Start_Location'])\n",
        "    if isinstance(cleaned, str) and cleaned != \"\":\n",
        "        lat, lon = get_lat_lon(cleaned)\n",
        "        if pd.notna(lat) and pd.notna(lon):\n",
        "            df.at[idx, 'Start_Latitude'] = lat\n",
        "            df.at[idx, 'Start_Longitude'] = lon\n",
        "            print(f\"âœ… Start filled: {row['Start_Location']} â†’ ({lat:.4f}, {lon:.4f})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ Start not found: {row['Start_Location']}\")\n",
        "\n",
        "# ---------- Fill missing END coordinates ----------\n",
        "missing_end = df[df['End_Latitude'].isna() | df['End_Longitude'].isna()]\n",
        "\n",
        "for idx, row in missing_end.iterrows():\n",
        "    cleaned = clean_location_name(row['End_Location'])\n",
        "    if isinstance(cleaned, str) and cleaned != \"\":\n",
        "        lat, lon = get_lat_lon(cleaned)\n",
        "        if pd.notna(lat) and pd.notna(lon):\n",
        "            df.at[idx, 'End_Latitude'] = lat\n",
        "            df.at[idx, 'End_Longitude'] = lon\n",
        "            print(f\"âœ… End filled: {row['End_Location']} â†’ ({lat:.4f}, {lon:.4f})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ End not found: {row['End_Location']}\")\n",
        "\n",
        "print(\"\\nâœ… All missing Start and End coordinates processed.\")\n",
        "print(\"Remaining missing values:\")\n",
        "print(\"Start_Latitude:\", df['Start_Latitude'].isna().sum())\n",
        "print(\"End_Latitude:\", df['End_Latitude'].isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc97x7owWedS"
      },
      "source": [
        "This script cleans and standardizes location names and fills in missing route information for the airline dataset.\n",
        "\n",
        "âš™ï¸ Step-by-Step Summary\n",
        "\n",
        "clean_location_name() function:\n",
        "\n",
        "Converts names to lowercase.\n",
        "\n",
        "Removes unnecessary words like â€œairportâ€, â€œinternationalâ€, etc.\n",
        "\n",
        "Removes text inside parentheses and extra punctuation/spaces.\n",
        "\n",
        "Returns a clean, properly capitalized location name.\n",
        "\n",
        "Cleans both location columns:\n",
        "\n",
        "Applies the cleaning function to Start_Location and End_Location.\n",
        "\n",
        "Fills missing routes:\n",
        "\n",
        "For any missing Route, constructs it as \"Start_Location to End_Location\".\n",
        "\n",
        "âœ… This ensures all routes are consistently formatted and complete, making the dataset ready for visualization and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKU1Nw0KWeP6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def clean_location_name(name):\n",
        "    if not isinstance(name, str):\n",
        "        return np.nan\n",
        "    name = name.lower()\n",
        "    name = re.sub(r'\\([^)]*\\)', '', name)  # remove text in parentheses\n",
        "    name = re.sub(r'\\b(international|airport|airpt|airlines?|terminal|int|intl)\\b', '', name)\n",
        "    name = re.sub(r'[-,]', ' ', name)\n",
        "    name = re.sub(r'\\s+', ' ', name)\n",
        "    return name.strip().title()\n",
        "\n",
        "# --- Clean Start and End locations ---\n",
        "df['Start_Location'] = df['Start_Location'].apply(clean_location_name)\n",
        "df['End_Location'] = df['End_Location'].apply(clean_location_name)\n",
        "\n",
        "# --- Fill missing Route values ---\n",
        "missing_routes = df['Route'].isna()\n",
        "df.loc[missing_routes, 'Route'] = df.loc[missing_routes].apply(\n",
        "    lambda row: f\"{row['Start_Location']} to {row['End_Location']}\"\n",
        "    if pd.notna(row['Start_Location']) and pd.notna(row['End_Location'])\n",
        "    else np.nan,\n",
        "    axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OfMm4eEWd52"
      },
      "source": [
        "We removed Layover_Route because it was:\n",
        "\n",
        "ðŸ§© Redundant â€” the main Route column (constructed as Start â†’ End) already represents the flight path. The layover doesnâ€™t add unique analytical value for most visualizations or sentiment insights.\n",
        "\n",
        "ðŸ“‰ Incomplete â€” only a small fraction of entries (484 out of 3575) had Layover_Route filled, making it too sparse to be useful for modeling or aggregation.\n",
        "\n",
        "ðŸ§¼ Simplifies the dataset â€” removing it makes the data cleaner and more consistent, focusing on core fields (Start_Location, End_Location, and Route) that are now complete and standardized.\n",
        "\n",
        "In short: it was mostly empty, repetitive, and unnecessary for your current analysis goals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAFmnE7qWdA9"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Layover_Route'])\n",
        "df = df.drop(columns=['Flying_Date'])\n",
        "print(\"âœ… Layover_Route removed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnQDTbeLWvlT"
      },
      "source": [
        "Perfect â€” that line saves your fully cleaned and standardized dataset to a CSV file named cleaned_airline_reviews.csv in your working directory.\n",
        "\n",
        "Hereâ€™s what it does:\n",
        "\n",
        "index=False â†’ prevents pandas from adding row numbers as an extra column.\n",
        "\n",
        "encoding='utf-8-sig' â†’ ensures correct encoding (especially for non-English text like Arabic city names).\n",
        "\n",
        "to_csv() â†’ writes the DataFrame to a CSV file that you can easily open in Excel, Power BI, or reload later for further analysis.\n",
        "\n",
        "In short:\n",
        "\n",
        "ðŸ’¾ Youâ€™ve successfully exported your final cleaned dataset â€” ready for analysis, visualization, or machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAnZowEMWwHq"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"cleaned_airline_reviews.csv\", index=False, encoding='utf-8-sig')\n",
        "print(\"âœ… Data exported to 'cleaned_airline_reviews.csv'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
